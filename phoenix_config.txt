#!/bin/bash
# phoenix_config.sh
# Configuration variables for Proxmox VE setup scripts
# Version: 1.3.1 (Updated for 3-drive setup: datasets moved to quickOS/fastData, storageNFS disabled)
# Author: Heads, Grok, Devstral, Assistant

# Source common functions (Note: Ensure logging is set up before sourcing if common.sh functions log)
# The orchestrator script should handle sourcing common.sh and setting up logging.
# source /usr/local/bin/common.sh|| { echo "Error: Failed to source common.sh"| tee -a /dev/stderr; exit 1; }

# --- Function to load configuration variables from environment or defaults ---
# This function should be called by the orchestrator script after sourcing this file.
load_config() {
    # --- SMB Configuration ---
    # SMB User (for Samba shares)
    SMB_USER="${SMB_USER:-heads}"
    export SMB_USER

    # --- Define ZFS pools and drives ---
    # quickOS: For local Proxmox zfspool storage (VMs, LXC) and shared data
    QUICKOS_POOL="quickOS"
    # fastData: For local directory storage (backups, ISOs, test/bulk data)
    FASTDATA_POOL="fastData"
    # storageNFS: Dedicated pool for datasets to be exported via NFS
    # --- DISABLED FOR 3-DRIVE SETUP ---
    # STORAGE_NFS_POOL="storageNFS"
    export QUICKOS_POOL FASTDATA_POOL #STORAGE_NFS_POOL

    # Drives are expected to be set by the orchestrator script (e.g., create_phoenix.sh)
    # export QUICKOS_DRIVES FASTDATA_DRIVE STORAGE_NFS_DRIVE

    # --- Define ZFS datasets and properties for each pool ---

    # --- quickOS Pool Datasets ---
    # List of datasets to create under quickOS pool
    QUICKOS_DATASET_LIST=(
        "vm-disks"    # For Proxmox VM disk images (zfspool)
        "lxc-disks"   # For Proxmox LXC container disk images (zfspool)
        # --- ADD MISSING DATASETS HERE (MOVED FROM storageNFS) ---
        "shared-prod-data"   # For shared LLM models, application data (Directory)
        "shared-prod-data-sync" # For databases requiring sync writes (Directory)
        # --- END ADDITION ---
        # Add more datasets here if needed for quickOS
    )
    # Associative array for properties of quickOS datasets
    # Format: dataset_name="property1=value1,property2=value2,..."
    declare -gA QUICKOS_DATASET_PROPERTIES
    QUICKOS_DATASET_PROPERTIES["vm-disks"]="compression=lz4,dedup=on"
    QUICKOS_DATASET_PROPERTIES["lxc-disks"]="compression=lz4"
    # --- ADD PROPERTIES FOR NEW DATASETS (BASED ON storage_requirements.txt) ---
    # Based on storage_requirements.txt suggestions
    QUICKOS_DATASET_PROPERTIES["shared-prod-data"]="compression=lz4,recordsize=128K,sync=standard,quota=400G"
    QUICKOS_DATASET_PROPERTIES["shared-prod-data-sync"]="compression=lz4,recordsize=16K,sync=always"
    # --- END ADDITION ---
    # Add properties for other quickOS datasets if needed
    export QUICKOS_DATASET_LIST
    # Exporting associative arrays requires a different approach, handled by scripts

    # --- fastData Pool Datasets ---
    # List of datasets to create under fastData pool
    FASTDATA_DATASET_LIST=(
        "shared-backups" # For Proxmox vzdump backups (directory)
        "shared-iso"     # For Proxmox ISO images (directory)
        # --- ADD MISSING DATASETS HERE (MOVED FROM storageNFS) ---
        "shared-test-data" # For test data, ML training sets (Directory)
        "shared-bulk-data" # For large, less frequently accessed data (Directory)
        # --- END ADDITION ---
        # Add more datasets here if needed for fastData
    )
    # Associative array for properties of fastData datasets
    declare -gA FASTDATA_DATASET_PROPERTIES
    FASTDATA_DATASET_PROPERTIES["shared-backups"]="compression=lz4"
    FASTDATA_DATASET_PROPERTIES["shared-iso"]="compression=lz4"
    # --- ADD PROPERTIES FOR NEW DATASETS (BASED ON storage_requirements.txt) ---
    # Based on storage_requirements.txt suggestions (adjust as needed)
    FASTDATA_DATASET_PROPERTIES["shared-test-data"]="compression=lz4,atime=off"
    FASTDATA_DATASET_PROPERTIES["shared-bulk-data"]="compression=lz4,atime=off"
    # --- END ADDITION ---
    # Add properties for other fastData datasets if needed
    export FASTDATA_DATASET_LIST
    # Exporting associative arrays requires a different approach, handled by scripts

    # --- storageNFS Pool Datasets (DISABLED FOR 3-DRIVE SETUP) ---
    # List of datasets to create under storageNFS pool
    # STORAGE_NFS_DATASET_LIST=(
    #     "shared-prod-data" # For shared LLM models, application data (NFS/dir) - MOVED TO quickOS
    #     "shared-prod-data-sync" # For databases requiring sync writes (NFS/dir) - MOVED TO quickOS
    #     "shared-test-data" # For test data, ML training sets (NFS/dir) - MOVED TO fastData
    #     # "shared-bulk-data" # For large, less frequently accessed data (NFS/dir) - MOVED TO fastData - Add if needed
    #     "shared-test-data-sync" # For test data requiring sync writes (NFS/dir)
    # )
    # # Associative array for properties of storageNFS datasets
    # declare -gA STORAGE_NFS_DATASET_PROPERTIES
    # STORAGE_NFS_DATASET_PROPERTIES["shared-prod-data"]="compression=lz4,recordsize=128K,sync=standard,quota=400G"
    # STORAGE_NFS_DATASET_PROPERTIES["shared-prod-data-sync"]="compression=lz4,recordsize=16K,sync=always"
    # STORAGE_NFS_DATASET_PROPERTIES["shared-test-data"]="compression=lz4,atime=off"
    # # STORAGE_NFS_DATASET_PROPERTIES["shared-bulk-data"]="compression=lz4,atime=off" # Add if moved here
    # STORAGE_NFS_DATASET_PROPERTIES["shared-test-data-sync"]="compression=lz4,atime=off,sync=always"
    # # Add properties for other storageNFS datasets if needed
    # export STORAGE_NFS_DATASET_LIST
    # # Exporting associative arrays requires a different approach, handled by scripts

    # --- Define dataset storage types ---
    # This array tells the storage creation script what type of Proxmox storage to create
    # Key: Full dataset path (e.g., quickOS/vm-disks, fastData/shared-backups)
    # Value: storage type and content ("zfspool:images", "dir:backup", etc.)
    declare -gA DATASET_STORAGE_TYPES
    # - quickOS datasets (ZFS Pool or Directory) -
    DATASET_STORAGE_TYPES["quickOS/vm-disks"]="zfspool:images"
    DATASET_STORAGE_TYPES["quickOS/lxc-disks"]="zfspool:rootdir"
    # - NEW ENTRIES FOR MOVED DATASETS -
    DATASET_STORAGE_TYPES["quickOS/shared-prod-data"]="dir:images" # Or maybe a more specific type?
    DATASET_STORAGE_TYPES["quickOS/shared-prod-data-sync"]="dir:images" # Or maybe a more specific type?
    # - END NEW ENTRIES -

    # - fastData datasets (Directory) -
    DATASET_STORAGE_TYPES["fastData/shared-backups"]="dir:backup"
    DATASET_STORAGE_TYPES["fastData/shared-iso"]="dir:iso,vztmpl"
    # - NEW ENTRIES FOR MOVED DATASETS -
    DATASET_STORAGE_TYPES["fastData/shared-test-data"]="dir:images" # Or maybe a more specific type?
    DATASET_STORAGE_TYPES["fastData/shared-bulk-data"]="dir:images" # Or maybe a more specific type?
    # - END NEW ENTRIES -

    # - storageNFS datasets (DISABLED) -
    # DATASET_STORAGE_TYPES["storageNFS/shared-prod-data"]="nfs:images" # DISABLED
    # DATASET_STORAGE_TYPES["storageNFS/shared-prod-data-sync"]="nfs:images" # DISABLED
    # DATASET_STORAGE_TYPES["storageNFS/shared-test-data"]="nfs:images" # DISABLED
    # DATASET_STORAGE_TYPES["storageNFS/shared-test-data-sync"]="nfs:images" # DISABLED
    # Add entries for other datasets if needed
    # Exporting associative arrays requires a different approach, handled by scripts

    # --- Define default Proxmox storage IDs ---
    # Customize these if you want different names in the Proxmox UI
    DEFAULT_STORAGE_ID_QUICKOS_VM="quickOS-vm"
    DEFAULT_STORAGE_ID_QUICKOS_LXC="quickOS-lxc"
    DEFAULT_STORAGE_ID_FASTDATA_BACKUP="fastData-backup"
    DEFAULT_STORAGE_ID_FASTDATA_ISO="fastData-iso"
    # DEFAULT_STORAGE_ID_STORAGENFS_BACKUP="storageNFS-backup" # DISABLED
    # DEFAULT_STORAGE_ID_STORAGENFS_ISO="storageNFS-iso"       # DISABLED
    export DEFAULT_STORAGE_ID_QUICKOS_VM DEFAULT_STORAGE_ID_QUICKOS_LXC \
           DEFAULT_STORAGE_ID_FASTDATA_BACKUP DEFAULT_STORAGE_ID_FASTDATA_ISO
           # DEFAULT_STORAGE_ID_STORAGENFS_BACKUP DEFAULT_STORAGE_ID_STORAGENFS_ISO

    echo "[$(date)] Configuration variables loaded and validated" >> "${LOGFILE:-/dev/stderr}"
}

# Call load_config if not already called by orchestrator (useful for standalone testing)
# load_config